# Vision Provider Configuration
# Options: openai, ollama, gemini, none
VISION_PROVIDER=ollama

# OpenAI Configuration (if using openai provider)
OPENAI_API_KEY=sk-...

# Ollama Configuration (if using ollama provider - LOCAL, FREE)
# Install: https://ollama.ai
# Then run: ollama pull llava
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llava

# Google Gemini Configuration (if using gemini provider - FREE TIER)
# Get API key: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash

# Table Processing
# Enable vision-based table extraction (requires good vision model like GPT-4V)
# Set to true only with OpenAI or Gemini - LLaVA has accuracy issues
ENABLE_TABLE_VISION=false

# File Handling
MAX_FILE_SIZE_MB=50

# Job timeout in seconds
JOB_TIMEOUT_SECONDS=300

# Temporary directory for processing files
TEMP_DIR=/tmp/paper_md

# Logging level
LOG_LEVEL=INFO
